{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F3g-_LGaZtWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d862e0d-33df-4369-ebd6-fbad74656763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-36b946a77228>:7: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records:                                             Sentence Sentiment\n",
            "0  The GeoSolutions technology will leverage Bene...  positive\n",
            "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
            "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
            "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
            "4  The Swedish buyout firm has sold its remaining...   neutral\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "file_path = \"data.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"sbhatti/financial-sentiment-analysis\",\n",
        "  file_path\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\", df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "\n",
        "print(\"First 5 rows of the DataFrame:\\n\", df.head())\n",
        "\n",
        "print(\"\\nShape of the DataFrame:\", df.shape)\n",
        "\n",
        "print(\"\\nInformation about the DataFrame:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nMissing values in the DataFrame:\\n\", df.isnull().sum())\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "print(\"\\nDistribution of sentiment labels:\\n\", df['Sentiment'].value_counts())"
      ],
      "metadata": {
        "id": "w9_xywhQaONZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e24df7-7d37-4f6d-ebdf-6c22e09df319"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "                                             Sentence Sentiment\n",
            "0  The GeoSolutions technology will leverage Bene...  positive\n",
            "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
            "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
            "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
            "4  The Swedish buyout firm has sold its remaining...   neutral\n",
            "\n",
            "Shape of the DataFrame: (5842, 2)\n",
            "\n",
            "Information about the DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5842 entries, 0 to 5841\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Sentence   5842 non-null   object\n",
            " 1   Sentiment  5842 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 91.4+ KB\n",
            "\n",
            "Missing values in the DataFrame:\n",
            " Sentence     0\n",
            "Sentiment    0\n",
            "dtype: int64\n",
            "\n",
            "Distribution of sentiment labels:\n",
            " Sentiment\n",
            "neutral     3130\n",
            "positive    1852\n",
            "negative     860\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "df['cleaned_sentence'] = df['Sentence'].apply(clean_text)\n",
        "print(\"Cleaned sentences:\\n\", df['cleaned_sentence'].head())\n"
      ],
      "metadata": {
        "id": "Uuvo0c_vbbXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6327d2c1-4459-4044-c2ac-8f28841728c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned sentences:\n",
            " 0    the geosolutions technology will leverage bene...\n",
            "1          esi on lows down  to  bk a real possibility\n",
            "2    for the last quarter of   componenta s net sal...\n",
            "3    according to the finnishrussian chamber of com...\n",
            "4    the swedish buyout firm has sold its remaining...\n",
            "Name: cleaned_sentence, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['Sentiment'])\n",
        "print(\"Encoded labels:\\n\", df['label'].value_counts())\n",
        "#1 is for neutral\n",
        "#2 is for positive\n",
        "#0 is for negative"
      ],
      "metadata": {
        "id": "G8cl8r1BbhAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b568e6a-749b-4cb4-9081-d53d6e1c83e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded labels:\n",
            " label\n",
            "1    3130\n",
            "2    1852\n",
            "0     860\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Limit features for efficiency\n",
        "X_tfidf = vectorizer.fit_transform(df['cleaned_sentence'])\n",
        "\n",
        "print(\"TF-IDF feature matrix shape:\", X_tfidf.shape)"
      ],
      "metadata": {
        "id": "kj6HTLPcb5kv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de1af936-6b82-46aa-a45e-8d24aa3f7f17"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF feature matrix shape: (5842, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "JZi4VBF2b_Q7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train the model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Print classification report for detailed metrics\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "qwAR0hnNcG5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c31a75a6-adcc-4846-c14b-02c58a37beb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.728\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.15      0.24       175\n",
            "           1       0.71      0.91      0.80       622\n",
            "           2       0.79      0.70      0.74       372\n",
            "\n",
            "    accuracy                           0.73      1169\n",
            "   macro avg       0.68      0.59      0.59      1169\n",
            "weighted avg       0.71      0.73      0.70      1169\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model\n",
        "with open(\"sentiment_model.pkl\", \"wb\") as model_file:\n",
        "    pickle.dump(model, model_file)\n",
        "\n",
        "# Save the vectorizer\n",
        "with open(\"tfidf_vectorizer.pkl\", \"wb\") as vectorizer_file:\n",
        "    pickle.dump(vectorizer, vectorizer_file)"
      ],
      "metadata": {
        "id": "NfjLVYjAcJaE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok"
      ],
      "metadata": {
        "id": "BP6AbELDfPlQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "547a0cbb-2b8a-4215-81fc-3e9d92fa195c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok --quiet"
      ],
      "metadata": {
        "id": "3tNuW7Zkhptb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2uU6McoAccmroZOncSzMuTfYeiH_5YBg47TufHEzJAiUP82q4"
      ],
      "metadata": {
        "id": "TNqF5P6ChLYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27600ec5-fe04-4e48-ba6e-3fa9d23e146a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import pickle\n",
        "import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio for Jupyter/Colab compatibility\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "with open(\"sentiment_model.pkl\", \"rb\") as model_file:\n",
        "    model = pickle.load(model_file)\n",
        "\n",
        "with open(\"tfidf_vectorizer.pkl\", \"rb\") as vectorizer_file:\n",
        "    vectorizer = pickle.load(vectorizer_file)\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Home route\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Financial News Sentiment Analyzer is running!\"\n",
        "\n",
        "# Sentiment analysis route\n",
        "@app.route('/analyze', methods=['POST'])\n",
        "def analyze_sentiment():\n",
        "    data = request.json['headline']\n",
        "    processed_data = vectorizer.transform([data])\n",
        "    prediction = model.predict(processed_data)[0]\n",
        "    return jsonify({\"sentiment\": prediction})\n",
        "\n",
        "# Start ngrok and expose the Flask app\n",
        "if __name__ == '__main__':\n",
        "    # Start ngrok tunnel\n",
        "    public_url = ngrok.connect(5000).public_url\n",
        "    print(f\" * ngrok tunnel: {public_url}\")\n",
        "\n",
        "    # Run the Flask app\n",
        "    app.run(host='0.0.0.0', port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX2ZGtIucM3M",
        "outputId": "7897e835-910e-4ad7-f7fc-92a882107ad0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel: https://6a55-34-168-31-17.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 10:51:43] \"\u001b[31m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 11:03:19] \"\u001b[31m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 11:04:07] \"\u001b[31m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 405 -\n"
          ]
        }
      ]
    }
  ]
}